{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> code {background-color : pink !important;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style> code {background-color : pink !important;} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Calibration with OpenCV\n",
    "===\n",
    "\n",
    "### The cell below will extract object points and image points for camera calibration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have objpoints and imgpoints needed for camera calibration.  \n",
    "The cell below calibrates, calculates distortion coefficients, and tests undistortion on an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Test undistortion on an image\n",
    "\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "#cv2.imwrite('calibration_wide/test_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open(\"camera_cal/calibrated1.p\", \"wb\") )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply distortion correction on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "from resizeimage.resize_cover import resize_cover\n",
    "\n",
    "test_images_path = 'test_images/'\n",
    "output_images_path = 'output_images/'\n",
    "test_images = os.listdir(test_images_path)\n",
    "test_set = []\n",
    "\n",
    "for image in test_images:\n",
    "    img = mpimg.imread(test_images_path+image)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    plt.imshow(dst)\n",
    "    #plt.savefig(output_images_path+image, dpi = 300)\n",
    "    plt.show()\n",
    "    resize_cover.save(output_images_path+image, test_image.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply gradient threholds\n",
    "\n",
    "Magnitude threshold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "\n",
    "    mag = np.sqrt(abs_sobelx*abs_sobelx + abs_sobely*abs_sobely)\n",
    "    scaled_mag = np.uint8(255 * mag / np.max(mag))\n",
    "\n",
    "    binary = np.zeros_like(scaled_mag)\n",
    "    binary[(scaled_mag >= mag_thresh[0]) & (scaled_mag <= mag_thresh[1])] = 1\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply gradient threholds\n",
    "\n",
    "Direction threshold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "\n",
    "    dir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary = np.zeros_like(dir)\n",
    "    binary[(dir > thresh[0]) & (dir < thresh[1])] = 1\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a test image with direction and magnitude thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "img = mpimg.imread(output_images_path+'test1.jpg')\n",
    "plt.gca().set_title('Original')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# find the magnitude of the gradient\n",
    "mag = mag_thresh(gray, sobel_kernel = 3, mag_thresh = (10, 100))\n",
    "plt.gca().set_title('Magnitude')\n",
    "plt.imshow(mag)\n",
    "plt.show()\n",
    "\n",
    "# find the direction of the gradient and apply threshold\n",
    "dir = dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/16))\n",
    "plt.gca().set_title('Direction')\n",
    "plt.imshow(dir)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
